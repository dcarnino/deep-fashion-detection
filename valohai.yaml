---

- step:
    name: Eval model
    image: dcarnino/docker-tensorflow-object-detection
    command:
      - cd /tensorflow/models/research/
      - export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim
      - cd object_detection/
      - mkdir -p training
      - cp /valohai/repository/ssd_inception_v2_coco.config training/
      - cp /valohai/repository/eval.py training/
      - mkdir training/data
      - cp /valohai/repository/deepfashion_label_map.pbtxt training/data/
      - mv /valohai/inputs/val_records/test.record /valohai/inputs/val_records/val.record
      - cp /valohai/inputs/val_records/val.record training/data/
      - unzip /valohai/inputs/trained_net/fine_tuned_model.zip -d training/
      - mv training/fine_tuned_model training/models
      - cp /valohai/repository/checkpoint training/models/
      - cd training/
      - mkdir models/eval
      - python3 eval.py --logtostderr --eval_dir=./models/eval --pipeline_config_path=ssd_inception_v2_coco.config --checkpoint_dir=./models
      - cd models
      - zip -r eval_val.zip eval
      - mv eval_val.zip /valohai/outputs/
    inputs:
      - name: val_records
      - name: trained_net
      
- step:
    name: Resume training
    image: dcarnino/docker-tensorflow-object-detection
    command:
      - nsteps=100
      - cd /tensorflow/models/research/
      - export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim
      - cd object_detection/
      - mkdir -p training
      - cp /valohai/repository/ssd_inception_v2_coco.config training/
      - cp /valohai/repository/train.py training/
      - sed -i -e "157s/200000/$nsteps/" training/ssd_inception_v2_coco.config
      - mkdir training/data
      - cp /valohai/repository/deepfashion_label_map.pbtxt training/data/
      - cp /valohai/inputs/train_records/train.record training/data/
      - cp /valohai/inputs/val_records/val.record training/data/
      - unzip /valohai/inputs/trained_net/fine_tuned_model.zip -d training/
      - mv training/fine_tuned_model training/models
      - mkdir training/models/train
      - cp export_inference_graph.py training/
      - cp /valohai/repository/checkpoint training/models/
      - cd training/
      - ls ./models/train/
      - python3 train.py --logtostderr --train_dir=./models/train --pipeline_config_path=ssd_inception_v2_coco.config
      - python3 export_inference_graph.py --input_type image_tensor --pipeline_config_path ./ssd_inception_v2_coco.config --trained_checkpoint_prefix ./models/train/model.ckpt-$nsteps --output_directory ./fine_tuned_model
      - zip -r fine_tuned_model.zip fine_tuned_model
      - mv fine_tuned_model.zip /valohai/outputs/
      - mv tensorflow.log /valohai/outputs/
    inputs:
      - name: train_records
      - name: val_records
      - name: trained_net

- step:
    name: Train model
    image: dcarnino/docker-tensorflow-object-detection
    command:
      - nsteps=100
      - cd /tensorflow/models/research/
      - export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim
      - cd object_detection/
      - mkdir -p training
      - cp /valohai/repository/ssd_inception_v2_coco.config training/
      - cp /valohai/repository/train.py training/
      - sed -i -e "157s/200000/$nsteps/" training/ssd_inception_v2_coco.config
      - mkdir training/data
      - cp /valohai/repository/deepfashion_label_map.pbtxt training/data/
      - cp /valohai/inputs/train_records/train.record training/data/
      - cp /valohai/inputs/val_records/val.record training/data/
      - mkdir training/models
      - tar -xzvf /valohai/inputs/pretrained_net/ssd_inception_v2_coco_2017_11_17.tar.gz -C training/models/ --strip-components=1
      - mkdir training/models/train
      - cp export_inference_graph.py training/
      - cd training/
      - python3 train.py --logtostderr --train_dir=./models/train --pipeline_config_path=ssd_inception_v2_coco.config
      - python3 export_inference_graph.py --input_type image_tensor --pipeline_config_path ./ssd_inception_v2_coco.config --trained_checkpoint_prefix ./models/train/model.ckpt-$nsteps --output_directory ./fine_tuned_model
      - zip -r fine_tuned_model.zip fine_tuned_model
      - mv fine_tuned_model.zip /valohai/outputs/
      - mv tensorflow.log /valohai/outputs/
    inputs:
      - name: train_records
      - name: val_records
      - name: pretrained_net
        default: http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2017_11_17.tar.gz

- step:
    name: Dataset preparation
    image: dcarnino/docker-tensorflow-object-detection
    command:
      - cd /tensorflow/models/research/
      - export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim
      - cp /valohai/repository/deep_fashion_to_tfrecord.py object_detection/
      - cd object_detection
      - mkdir -p category_and_attribute_prediction_benchmark
      - echo "Downloading from Google Drive..."
      - CONFIRM=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate "https://docs.google.com/uc?export=download&id=1eFP3_HApf-AsYF--0OIlDNSdWevn0byq" -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')
      - wget --load-cookies /tmp/cookies.txt "https://docs.google.com/uc?export=download&confirm=$CONFIRM&id=1eFP3_HApf-AsYF--0OIlDNSdWevn0byq" -O /valohai/inputs/category_and_attribute_prediction_benchmark/AACt2dLasqSDsCf-kcQwoWyfa
      - rm -rf /tmp/cookies.txt
      - echo "Unzipping deep fashion dataset..."
      - unzip -q /valohai/inputs/category_and_attribute_prediction_benchmark/AACt2dLasqSDsCf-kcQwoWyfa -d category_and_attribute_prediction_benchmark/
      - mv category_and_attribute_prediction_benchmark/AACt2dLasqSDsCf-kcQwoWyfa ./AACt2dLasqSDsCf-kcQwoWyfa
      - mv ./AACt2dLasqSDsCf-kcQwoWyfa/* category_and_attribute_prediction_benchmark/
      - cd category_and_attribute_prediction_benchmark/Img/
      - unzip -q img.zip
      - cd ../../
      - echo "Formatting training images to tfrecord..."
      - python3 deep_fashion_to_tfrecord.py --output_path train.record --categories broad --evaluation_status train
      - echo "Formatting validation images to tfrecord..."
      - python3 deep_fashion_to_tfrecord.py --output_path val.record --categories broad --evaluation_status val
      - echo "Formatting test images to tfrecord..."
      - python3 deep_fashion_to_tfrecord.py --output_path test.record --categories broad --evaluation_status test
      - mv *.record /valohai/outputs/
    inputs:
      - name: category_and_attribute_prediction_benchmark
        default: https://www.dropbox.com/sh/ryl8efwispnjw21/AACt2dLasqSDsCf-kcQwoWyfa?dl=1

- step:
    name: Worker environment check
    image: dcarnino/docker-tensorflow-object-detection
    command:
      - pwd
      - ls -la
      - ls /tensorflow/
      - nvidia-smi
      - python --version
      - nvcc --version | grep release
      - cat /usr/include/x86_64-linux-gnu/cudnn_v*.h | grep CUDNN_MAJOR -A 2
      - cd /tensorflow/models/research/
      - export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim
      - python3 object_detection/builders/model_builder_test.py
